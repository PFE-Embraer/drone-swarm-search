{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Installing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Test Random Environment with PettingZoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pettingzoo.mpe import simple_v2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_env = simple_v2.parallel_env(max_cycles=30, continuous_actions=False)\n",
    "observations = parallel_env.reset()\n",
    "\n",
    "agent = parallel_env.agents[0]\n",
    "\n",
    "observation_space = parallel_env.observation_space(agent)\n",
    "action_space = parallel_env.action_space(agent)\n",
    "\n",
    "parallel_env.observation_space = observation_space\n",
    "parallel_env.action_space = action_space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:-38.75532836783367\n",
      "Episode:2 Score:-103.92529846244271\n",
      "Episode:3 Score:-75.43644400411934\n",
      "Episode:4 Score:-12.102438417653616\n",
      "Episode:5 Score:-147.91176842037106\n",
      "Episode:6 Score:-28.089079712596412\n",
      "Episode:7 Score:-73.36012172863425\n",
      "Episode:8 Score:-102.08646601151612\n",
      "Episode:9 Score:-56.77522873301166\n",
      "Episode:10 Score:-1.6591935670257663\n"
     ]
    }
   ],
   "source": [
    "episodes = 10\n",
    "for episode in range(1, episodes + 1):\n",
    "    state = parallel_env.reset()[agent]\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    while not done:\n",
    "        action = np.random.randint(0, action_space.n)\n",
    "        n_state, reward, _, done, _ = parallel_env.step({agent: action})\n",
    "        n_state = n_state[agent]\n",
    "        reward = reward[agent]\n",
    "        done = done[agent]\n",
    "\n",
    "        score += reward\n",
    "        state = n_state\n",
    "\n",
    "    print(\"Episode:{} Score:{}\".format(episode, score))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create Deep Learning Model with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-09 19:31:19.626470: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(learning_rate, action_space):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(1,) + observation_space.shape))\n",
    "    model.add(Dense(24, activation=\"relu\"))\n",
    "    model.add(Dense(24, activation=\"relu\"))\n",
    "    model.add(Dense(action_space.n, activation=\"linear\"))\n",
    "    model.compile(loss=\"mse\", optimizer=Adam(lr=learning_rate))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "model = build_model(0.001, action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 24)                120       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 24)                600       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 5)                 125       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 845\n",
      "Trainable params: 845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build Agent with Keras-RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl.agents import DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy\n",
    "from rl.memory import SequentialMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_agent(model, action_space):\n",
    "    policy = BoltzmannQPolicy()\n",
    "    memory = SequentialMemory(limit=50000, window_length=1)\n",
    "    dqn = DQNAgent(\n",
    "        model=model,\n",
    "        memory=memory,\n",
    "        policy=policy,\n",
    "        nb_actions=action_space.n,\n",
    "        nb_steps_warmup=10,\n",
    "        target_model_update=1e-2,\n",
    "    )\n",
    "    return dqn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-09 19:50:46.414347: W tensorflow/c/c_api.cc:300] Operation '{name:'dense_5_2/kernel/Assign' id:640 op device:{requested: '', assigned: ''} def:{{{node dense_5_2/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_5_2/kernel, dense_5_2/kernel/Initializer/stateless_random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Adam' object has no attribute '_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m dqn \u001b[39m=\u001b[39m build_agent(model, action_space)\n\u001b[0;32m----> 2\u001b[0m dqn\u001b[39m.\u001b[39;49mcompile(Adam(learning_rate\u001b[39m=\u001b[39;49m\u001b[39m1e-3\u001b[39;49m), metrics\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mmae\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m      3\u001b[0m dqn\u001b[39m.\u001b[39mfit(parallel_env, nb_steps\u001b[39m=\u001b[39m\u001b[39m50000\u001b[39m, visualize\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/rl/agents/dqn.py:175\u001b[0m, in \u001b[0;36mDQNAgent.compile\u001b[0;34m(self, optimizer, metrics)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_model_update \u001b[39m<\u001b[39m \u001b[39m1.\u001b[39m:\n\u001b[1;32m    173\u001b[0m     \u001b[39m# We use the `AdditionalUpdatesOptimizer` to efficiently soft-update the target model.\u001b[39;00m\n\u001b[1;32m    174\u001b[0m     updates \u001b[39m=\u001b[39m get_soft_target_model_updates(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_model, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_model_update)\n\u001b[0;32m--> 175\u001b[0m     optimizer \u001b[39m=\u001b[39m AdditionalUpdatesOptimizer(optimizer, updates)\n\u001b[1;32m    177\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclipped_masked_error\u001b[39m(args):\n\u001b[1;32m    178\u001b[0m     y_true, y_pred, mask \u001b[39m=\u001b[39m args\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/rl/util.py:86\u001b[0m, in \u001b[0;36mAdditionalUpdatesOptimizer.__init__\u001b[0;34m(self, optimizer, additional_updates)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, optimizer, additional_updates):\n\u001b[0;32m---> 86\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(optimizer\u001b[39m.\u001b[39;49m_name)\n\u001b[1;32m     87\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer \u001b[39m=\u001b[39m optimizer\n\u001b[1;32m     88\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madditional_updates \u001b[39m=\u001b[39m additional_updates\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Adam' object has no attribute '_name'"
     ]
    }
   ],
   "source": [
    "dqn = build_agent(model, action_space)\n",
    "dqn.compile(Adam(learning_rate=1e-3), metrics=[\"mae\"])\n",
    "dqn.fit(parallel_env, nb_steps=50000, visualize=False, verbose=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
